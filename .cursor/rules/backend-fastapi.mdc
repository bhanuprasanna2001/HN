---
globs: backend/**/*.py
---

# Backend — FastAPI + Python Rules

## Framework & Dependencies
- **Framework**: FastAPI with uvicorn (ASGI)
- **Python version**: 3.11+
- **Package manager**: Poetry or pip with pyproject.toml
- **Key dependencies**: fastapi, uvicorn, langchain, langgraph, langgraph-checkpoint-redis, redis, pydantic, opentelemetry-*, evidently, openpyxl, sentence-transformers (or openai for embeddings), sse-starlette

## API Design — Runs-Based Architecture
- All routes under `/api/v1/` prefix
- **Run lifecycle** (every question creates a "run"):
  - `POST /api/v1/runs` — Create a new run (submit question). Returns `{ run_id, status: "created" }`
  - `GET  /api/v1/runs/{run_id}/events` — **SSE stream** (`text/event-stream`). Streams agent step events + answer tokens in real time
  - `GET  /api/v1/runs/{run_id}` — Final structured result (answer + citations + triage + confidence + trace_id). Available after run completes
  - `POST /api/v1/runs/{run_id}/approve` — HITL decision (approve/reject/edit) for a run that paused at the HITL gate
  - `POST /api/v1/runs/{run_id}/cancel` — Cancel an in-progress run
- **Supporting endpoints**:
  - `POST /api/v1/learn` — Trigger learning event from a resolved case
  - `GET  /api/v1/metrics` — Trust metrics + drift summary
  - `GET  /api/v1/metrics/drift` — Evidently drift reports
  - `GET  /api/v1/retrieve` — Direct retrieval endpoint (for eval/debug)
  - `GET  /api/v1/retrieve/eval` — Retrieval accuracy evaluation (hit@k)
  - `GET  /api/v1/learning-events` — List pending/approved/rejected learning events
  - `GET  /api/v1/kb-articles` — Browse knowledge articles with filters
- **Streaming via SSE only** — no WebSockets
  - Use `sse-starlette`'s `EventSourceResponse` for the `/runs/{run_id}/events` endpoint
  - SSE provides: auto-reconnect (built into browser `EventSource` API), simpler infra (standard HTTP), no upgrade handshake
  - Each SSE event has `event:` type and `data:` JSON payload (see SSE Event Schema below)

## SSE Event Schema
Events streamed on `GET /api/v1/runs/{run_id}/events`:
```
event: triage
data: {"result": "KB", "confidence": 0.91}

event: retrieval
data: {"docs": [...], "scores": [...], "count": 5}

event: policy
data: {"passed": true, "violations": []}

event: token
data: {"content": "To resolve..."}

event: citation
data: {"source_id": "KB-xxx", "excerpt": "...", "relevance": 0.92}

event: learning
data: {"event_id": "LEARN-xxx", "gap": "...", "draft_id": "KB-SYN-xxx"}

event: approval_required
data: {"event_id": "LEARN-xxx", "run_id": "..."}

event: done
data: {"confidence": 0.87, "trace_id": "abc123", "run_id": "..."}

event: error
data: {"message": "...", "code": "POLICY_VIOLATION"}

event: heartbeat
data: {}
```

## SSE Reliability
- **Heartbeats**: Send `event: heartbeat` every 15s on idle streams. Some proxies/load balancers kill connections that appear idle. A periodic heartbeat keeps the connection alive.
- **Reconnect-safe buffering**: Buffer SSE events per `run_id` in a Redis Stream (or List with TTL). If the browser's `EventSource` reconnects (auto-reconnect sends `Last-Event-ID` header), replay missed events from the buffer. Include an `id:` field on every SSE event for this to work:
  ```
  id: 7
  event: token
  data: {"content": "To resolve..."}
  ```
- **Terminal events**: On `done` or `error`, close the SSE stream server-side. The event buffer for that `run_id` can be expired after 5 minutes (enough for late reconnects).

## Pydantic Models
- Every request/response must be a Pydantic v2 BaseModel
- Use `model_config = ConfigDict(strict=True)` where appropriate
- Define models in `backend/app/models/` organized by domain:
  - `runs.py` — CreateRunRequest, RunResponse, RunStatus, Citation, RetrievalResult
  - `learn.py` — LearningEvent, KBDraft, ApprovalRequest, ApprovalDecision
  - `metrics.py` — TrustMetrics, DriftAlert, DriftReport
- Response models must always include:
  - `answer` or `result` field
  - `citations: list[Citation]` (provenance is non-negotiable)
  - `confidence: float` (0.0–1.0)
  - `trace_id: str` (OTel trace for debugging)

## Error Handling
- Use FastAPI exception handlers for structured error responses
- Never return raw stack traces to the client
- All errors return: `{"error": str, "code": str, "trace_id": str}`
- Policy violations return 422 with specific violation details
- Escalation signals return 200 with `escalate: true` flag (not an error)

## Async Patterns
- All route handlers must be `async def`
- Use `asyncio` for concurrent operations (e.g., parallel retrieval + policy check)
- Redis operations via `redis.asyncio` client
- Never use `time.sleep()` — use `asyncio.sleep()` if needed
- Background tasks via FastAPI's `BackgroundTasks` for non-blocking post-processing

## Configuration
- All config via environment variables loaded through Pydantic `BaseSettings`
- Single config class in `backend/app/core/config.py`
- Required config: `REDIS_URL`, `LLM_MODEL`, `LLM_API_KEY`, `EMBEDDING_MODEL`, `OTEL_EXPORTER_ENDPOINT`
- Optional config with sane defaults: `RETRIEVAL_TOP_K=5`, `CONFIDENCE_THRESHOLD=0.7`, `MAX_TOKENS=2048`

## Security
- CORS configured to allow only the frontend origin (and localhost in dev)
- Rate limiting on `/runs` endpoint (run creation)
- Input sanitization on all user-provided text before passing to LLM
- Never pass raw user input as system prompts
- Log all policy violations as OTel events

## Startup / Lifespan
- Use FastAPI lifespan context manager for:
  - Redis connection pool initialization
  - OTel tracer/meter provider setup
  - Embedding model warmup (if local)
  - Health check for Redis connectivity
  - LangGraph checkpointer initialization (for durable run state)
