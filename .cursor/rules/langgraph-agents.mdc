---
globs: backend/app/agents/**/*.py
---

# LangGraph Agent Orchestration Rules

## Architecture: Single StateGraph with 7 Nodes
The entire support workflow is ONE LangGraph StateGraph, not separate chains.

```
┌─────────────┐
│ TriageAgent  │ ← Classifies: KB / SCRIPT / ESCALATE
└──────┬───────┘
       │
┌──────▼────────┐
│ RetrievalAgent │ ← Redis vector search + metadata filters
└──────┬────────┘
       │
┌──────▼─────────┐
│ PolicyGuardAgent│ ← OWASP + compliance checks
└──────┬─────────┘
       │
┌──────▼───────┐
│  AnswerAgent  │ ← Structured JSON + citations or REFUSE
└──────┬───────┘
       │ (if confidence < threshold OR gap detected)
┌──────▼────────┐
│ LearningAgent  │ ← Draft KB article + lineage
└──────┬────────┘
       │
┌──────▼───────┐
│   HITL Gate   │ ← LangGraph interrupt — pause for human approval
└──────┬───────┘
       │ (on approval)
┌──────▼────────┐
│ PublishAgent   │ ← Version + re-embed + re-index in Redis
└───────────────┘
```

## State Schema
Define a single TypedDict as the graph state:
```python
class TrustOpsState(TypedDict):
    # Input
    question: str
    session_id: str
    # Triage
    triage_result: Literal["KB", "SCRIPT", "ESCALATE"]
    triage_confidence: float
    # Retrieval
    retrieved_docs: list[RetrievedDocument]
    retrieval_scores: list[float]
    # Policy
    policy_violations: list[PolicyViolation]
    policy_passed: bool
    # Answer
    answer: str
    citations: list[Citation]
    confidence: float
    # Learning
    learning_event: Optional[LearningEvent]
    kb_draft: Optional[KBDraft]
    # HITL
    approval_status: Optional[Literal["PENDING", "APPROVED", "REJECTED", "EDITED"]]
    reviewer_notes: Optional[str]
    # Observability
    trace_id: str
    step_latencies: dict[str, float]
```

## Node Implementation Rules

### TriageAgent
- Uses LLM with structured output to classify question type
- Must return one of: KB, SCRIPT, ESCALATE
- Confidence score determines routing: < 0.5 → ESCALATE
- Input: question text + conversation context
- Output: triage_result, triage_confidence

### RetrievalAgent
- Queries Redis vector index with appropriate filters based on triage_result
- If triage_result == "KB" → search Knowledge_Articles index
- If triage_result == "SCRIPT" → search Scripts_Master index
- Always returns top-k results with relevance scores
- Must log retrieval latency as OTel metric
- Output: retrieved_docs, retrieval_scores

### PolicyGuardAgent (OWASP-Mapped Governable Control Plane)
- Runs BEFORE answer generation (pre-guard) AND after (post-guard)
- **Every blocked action must cite a specific policy rule + its OWASP risk class**

#### Pre-guard checks (before answer generation):
- Input sanitization (strip injection patterns)
- Prompt injection detection
- PII detection in user input
- Check retrieved docs are from Published status only

#### Post-guard checks (after answer generation):
- Citation requirement: every factual claim must have a citation
- Confidence threshold: refuse if below configured minimum
- Sensitive content check: no PCI data, no credentials, no discriminatory language
- Allowlisted tools check: agent can only use approved tools

#### OWASP LLM Top 10 (2025) Mapping — each policy references a specific risk:
| Policy | OWASP Risk | Control |
|--------|-----------|---------|
| `prompt_injection_policy` | **LLM01: Prompt Injection** | Input sanitization, system/user prompt separation, instruction boundary enforcement |
| `insecure_output_policy` | **LLM02: Insecure Output Handling** | Structured JSON output validation, no raw LLM text pass-through |
| `corpus_integrity_policy` | **LLM05: Supply Chain Vulnerabilities** (+ LLM03 if corpus poisoning) | Only retrieve from verified/published KB + scripts corpus; unpublished docs excluded from RAG |
| `sensitive_info_policy` | **LLM06: Sensitive Information Disclosure** | PII/PCI pattern detection + redaction before output |
| `excessive_agency_policy` | **LLM08: Excessive Agency** | Agent can ONLY query Redis and generate text — no file access, no external calls |
| `overreliance_policy` | **LLM09: Overreliance** | Citation-required output; confidence score surfaced; refuse-on-miss prevents blind trust |

#### OWASP Agentic Top 10 (2026) Mapping — official ASI IDs:
| Policy | OWASP Agentic Risk | Control |
|--------|-------------------|---------|
| `goal_hijack_policy` | **ASI01: Agent Goal & Instruction Hijack** | Fixed system instructions, user input isolated from agent goals |
| `tool_misuse_policy` | **ASI02: Tool Misuse & Exploitation** | Allowlisted tools only, no dynamic tool registration |
| `privilege_abuse_policy` | **ASI03: Identity & Privilege Abuse** | Role-based policy enforcement, no self-modification of policies |
| `memory_poisoning_policy` | **ASI06: Memory & Context Poisoning** | Conversation context TTL, no persistent memory mutation by user input |
| `cascading_failure_policy` | **ASI08: Cascading Failures** | Citation-required output, refuse if retrieval confidence < threshold, graceful degradation per node |

- If ANY policy fails → refuse to answer, log violation with OWASP risk ID, suggest escalation
- Violations surfaced in SSE events AND recorded as OTel span events with `owasp.risk_id` attribute
- Output: policy_violations (list with `{policy_name, owasp_risk_id, description, severity}`), policy_passed

### AnswerAgent
- Generates answer ONLY from retrieved documents (no hallucination)
- MUST include citations for every factual claim
- Uses structured output (JSON) with explicit citation references
- If retrieval scores are all below threshold → refuse and trigger LearningAgent
- For SCRIPT answers: include required inputs from Placeholder_Dictionary
- Output: answer, citations, confidence

### LearningAgent
- Triggered when: confidence < threshold, or retrieval misses, or new resolution pattern detected
- Drafts a KB article from: ticket resolution + transcript + script outputs
- Includes lineage metadata: source ticket, source conversation, source script
- Runs QA rubric from QA_Evaluation_Prompt tab against the draft
- Output: learning_event, kb_draft

### HITL Gate (LangGraph Interrupts — Canonical Pattern)
LangGraph owns the pause/resume lifecycle. Do NOT implement ad-hoc state serialization.

- Use `interrupt()` inside the HITL node to **pause the graph execution**
- LangGraph persists the graph state to its checkpointer (backed by Redis)
- The interrupted run exposes the KB draft + evidence to the frontend via the runs API
- Frontend calls `POST /api/v1/runs/{run_id}/approve` with the human decision
- Backend resumes the graph using `graph.invoke(Command(resume=decision), config={"configurable": {"thread_id": run_id}})`
- LangGraph picks up execution exactly where `interrupt()` paused

Implementation:
```python
# In the HITL node:
def hitl_gate(state: TrustOpsState) -> TrustOpsState:
    # Present draft to human, pause execution
    decision = interrupt({
        "kb_draft": state["kb_draft"],
        "learning_event": state["learning_event"],
        "evidence": state["retrieved_docs"],
    })
    # Execution resumes here when human responds
    return {**state, "approval_status": decision["status"], "reviewer_notes": decision.get("notes")}
```

- On APPROVE → proceed to PublishAgent
- On REJECT → archive with reviewer notes, skip PublishAgent
- On EDIT → update draft content in state, re-run QA rubric, then proceed to PublishAgent
- **Redis-backed checkpointer**: use `langgraph-checkpoint-redis` integration package (`from langgraph.checkpoint.redis import RedisSaver`) for durable state across restarts. This is a separate pip package, not built into core LangGraph.
- Output: approval_status, reviewer_notes

### PublishAgent
- Versions the new KB article (increment version, timestamp)
- Generates embedding for the new article
- Indexes into Redis vector store
- Updates KB_Lineage with provenance chain
- Emits OTel event: "kb_published" with article_id and lineage
- Output: updated state confirming publication

## Streaming via SSE
- Use LangGraph's streaming API (`graph.astream_events()`) to emit tokens/events per node
- Backend converts LangGraph stream events into SSE events on `GET /api/v1/runs/{run_id}/events`
- Each node emits structured SSE events the frontend can render progressively
- SSE event types: `triage`, `retrieval`, `policy`, `token`, `citation`, `learning`, `approval_required`, `done`, `error`
- No WebSockets — SSE is the only streaming mechanism

## Error Handling in Graph
- Each node wraps execution in try/except
- On node failure: log error span, set state error field, route to a graceful degradation path
- Never let a single node failure crash the entire graph
- Timeout per node: 30s default (configurable)

## Testing
- Each node must be independently testable with mock state
- End-to-end graph tests using Questions tab ground truth
- Policy guard tests with adversarial inputs (prompt injection attempts)
